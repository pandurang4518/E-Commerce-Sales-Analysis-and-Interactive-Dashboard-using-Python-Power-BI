{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f33575fd-2372-44f7-b6db-01920584857a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OrderID   Product        Category Region CustomerType       Month  \\\n",
      "0        1     Jeans        Clothing   West       Repeat  2023-06-30   \n",
      "1        2     Mixer  Home & Kitchen   West       Repeat  2024-04-30   \n",
      "2        3     Chair  Home & Kitchen  South          New  2024-10-31   \n",
      "3        4  Textbook           Books  South          New  2024-01-31   \n",
      "4        5  Lipstick          Beauty  North          New  2023-06-30   \n",
      "\n",
      "   UnitPrice  Quantity  Revenue  \n",
      "0        388         8     3104  \n",
      "1        414         1      414  \n",
      "2        194         7     1358  \n",
      "3        181         4      724  \n",
      "4        301         3      903  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   OrderID       100000 non-null  int64 \n",
      " 1   Product       100000 non-null  object\n",
      " 2   Category      100000 non-null  object\n",
      " 3   Region        100000 non-null  object\n",
      " 4   CustomerType  100000 non-null  object\n",
      " 5   Month         100000 non-null  object\n",
      " 6   UnitPrice     100000 non-null  int64 \n",
      " 7   Quantity      100000 non-null  int64 \n",
      " 8   Revenue       100000 non-null  int64 \n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 6.9+ MB\n",
      "None\n",
      "OrderID         0\n",
      "Product         0\n",
      "Category        0\n",
      "Region          0\n",
      "CustomerType    0\n",
      "Month           0\n",
      "UnitPrice       0\n",
      "Quantity        0\n",
      "Revenue         0\n",
      "dtype: int64\n",
      "Duplicates: 0\n",
      "Shape of dataset (rows, columns): (100000, 9)\n",
      "Number of rows: 100000\n",
      "Number of columns: 9\n",
      "✅ Data successfully ingested into table 'EcommerceSales'\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 1. Import required libraries\n",
    "# ==========================================\n",
    "import pandas as pd \n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# ==========================================\n",
    "# 2. Configure logging\n",
    "# ==========================================\n",
    "# Make sure \"logs\" folder exists\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"logs/ingestion_db.log\",   # log file path\n",
    "    level=logging.DEBUG,                # log level\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\", \n",
    "    filemode=\"a\"                        # append mode\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 3. Create SQLite Database Connection\n",
    "# ==========================================\n",
    "engine = create_engine('sqlite:///Ecommerce.db')\n",
    "\n",
    "# ==========================================\n",
    "# 4. Load CSV dataset into DataFrame\n",
    "# ==========================================\n",
    "df = pd.read_csv(r\"C:\\Users\\Dell\\Downloads\\ecommerce_sales_dataset_large.csv\")\n",
    "\n",
    "# Preview dataset\n",
    "print(df.head())\n",
    "\n",
    "# Dataset info\n",
    "print(df.info())\n",
    "print(df.isnull().sum())\n",
    "print(\"Duplicates:\", df.duplicated().sum())\n",
    "\n",
    "# Number of rows and columns\n",
    "print(\"Shape of dataset (rows, columns):\", df.shape)\n",
    "print(\"Number of rows:\", df.shape[0])\n",
    "print(\"Number of columns:\", df.shape[1])\n",
    "\n",
    "# ==========================================\n",
    "# 5. Function to ingest DataFrame into SQLite DB\n",
    "# ==========================================\n",
    "def ingest_db(df, table_name, engine):\n",
    "    \"\"\"\n",
    "    Function to store a DataFrame into a SQLite database table.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The pandas DataFrame to store.\n",
    "    table_name (str): Name of the SQL table.\n",
    "    engine (Engine): SQLAlchemy engine object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df.to_sql(table_name, con=engine, if_exists='replace', index=False)\n",
    "        print(f\"✅ Data successfully ingested into table '{table_name}'\")\n",
    "        logging.info(f\"Data successfully ingested into table '{table_name}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error ingesting data into table '{table_name}': {e}\")\n",
    "        logging.error(f\"Error ingesting data into table '{table_name}': {e}\")\n",
    "\n",
    "# ==========================================\n",
    "# 6. Ingest loaded dataset into DB\n",
    "# ==========================================\n",
    "ingest_db(df, \"EcommerceSales\", engine)\n",
    "\n",
    "# ==========================================\n",
    "# 7. Function to ingest all CSV files in 'data/' folder\n",
    "# ==========================================\n",
    "def load_raw_data():\n",
    "    \"\"\"\n",
    "    This function will load all CSV files in 'data' folder \n",
    "    and ingest them into SQLite database.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    # Ensure data folder exists\n",
    "    if not os.path.exists('data'):\n",
    "        os.makedirs('data')\n",
    "        logging.warning(\"'data' folder was missing. Created an empty one.\")\n",
    "    \n",
    "    for file in os.listdir('data'):\n",
    "        if file.endswith('.csv'):\n",
    "            try:\n",
    "                df = pd.read_csv(os.path.join('data', file))\n",
    "                logging.info(f\"Ingesting {file} into DB...\")\n",
    "                ingest_db(df, file[:-4], engine)  # table name without '.csv'\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to ingest {file}: {e}\")\n",
    "    \n",
    "    end = time.time()\n",
    "    total_time = (end - start) / 60\n",
    "    logging.info(\".......Ingestion complete........\")\n",
    "    logging.info(f\"Total time taken: {total_time:.2f} minutes\")\n",
    "    print(\"✅ All CSV files from 'data/' folder ingested successfully!\")\n",
    "\n",
    "# ==========================================\n",
    "# 8. Run load_raw_data() if needed\n",
    "# ==========================================\n",
    "# load_raw_data()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b7a42f-94e8-4846-a852-204442a182ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Reconnect to DB\n",
    "engine = create_engine('sqlite:///Ecommerce.db')\n",
    "\n",
    "# Load all data from EcommerceSales table\n",
    "df_all = pd.read_sql(\"SELECT * FROM EcommerceSales\", con=engine)\n",
    "\n",
    "# Show first 5 rows\n",
    "print(df_all.head())\n",
    "\n",
    "# Show total rows & columns\n",
    "print(\"Shape of dataset:\", df_all.shape)\n",
    "\n",
    "# If you want to see entire dataset (⚠️ careful with very large data)\n",
    "# print(df_all.to_string())   # This will print ALL rows (not recommended for 1L+ rows)\n",
    "\n",
    "# Better option: display only first 100 rows\n",
    "print(df_all.head(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef5e2de-0de2-4cac-9607-c253aa11bcd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17e9cdf8-422d-479e-9bde-9a8137b326d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf37659-83a3-4d67-976d-5ffe1c8e1f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abdd4f3-05e4-40e9-9362-b38a2e6db5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
